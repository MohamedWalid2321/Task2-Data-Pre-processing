{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb52c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from rapidfuzz import process,fuzz\n",
    "import unidecode\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")   # or \"Qt5Agg\" if you have PyQt installed\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18367da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23c56fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning process\n",
    "\n",
    "#1) chech for missing values and calculating the percentage of missing values per column\n",
    "print(data.isnull().sum())\n",
    "print((data.isnull().sum()/len(data))*100)\n",
    "\n",
    "#data is not having any missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9578a3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) check for duplicated values\n",
    "data.duplicated().any() # returns True if there are any duplicated rows, False otherwise\n",
    "data.duplicated().sum() # returns the number of duplicated rows\n",
    "data[data.duplicated()] # returns the duplicated rows\n",
    "\n",
    "#data is not having any duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "31360b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction ID               int64\n",
      "Date                datetime64[ns]\n",
      "Product Category            object\n",
      "Product Name                object\n",
      "Units Sold                   int64\n",
      "Unit Price                 float64\n",
      "Total Revenue              float64\n",
      "Region                      object\n",
      "Payment Method              object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#3) Handle inconsistent data entries\n",
    "#check if the columns is in the right data type\n",
    "\n",
    "print(data.dtypes)\n",
    "# we have Date as object we need to convert it to datetime64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c95f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_col=data[['Product Name','Date','Product Category','Region','Payment Method']]\n",
    "for col in object_col:\n",
    "    data[col].str.strip() #this removes the space at the beginning and end of the string\n",
    "data.to_csv('Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e12e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date'] = pd.to_datetime(data['Date'], dayfirst=True, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561439e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize categorical values\n",
    "\n",
    "data['Date'].value_counts()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950b1600",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Product Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = data['Product Name'].unique()\n",
    "similar_pairs=[]\n",
    "for product in choices:\n",
    "    matches = process.extract(product, choices, limit=None, scorer=fuzz.partial_ratio)\n",
    "    for match, score,index in matches:\n",
    "        if score >=75 and product !=match:\n",
    "            pair=tuple(sorted([product,match]))\n",
    "            if pair not in similar_pairs:\n",
    "                similar_pairs.append((pair[0],pair[1],score)) \n",
    "\n",
    "for p1,p2,score in similar_pairs:\n",
    "    print(f\"'{p1}' and '{p2}' have a similarity score of {score}\") \n",
    "\n",
    "data['Product Name'].replace('MacBook Pro 16-inch','Apple MacBook Pro 16-inch',inplace=True)\n",
    "data['Product Name'].replace('Nike Air Force 1','Nike Air Force 1 Sneakers',inplace=True)\n",
    "data['Product Name'].replace('Adidas Ultraboost Shoes','Adidas Ultraboost Running Shoes',inplace=True)\n",
    "data['Product Name'].replace('Yeti Rambler Tumbler','Yeti Rambler 20 oz Tumbler',inplace=True)\n",
    "data.to_csv('Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bb6bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1d3408",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Payment Method'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984b6d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for non-ASCII characters in 'Product Name' column\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "mask=data['Product Name'].apply(lambda x: not all(ord(c) <128 for c in str(x))) \n",
    "#this returns a boolean series where True indicates the presence of non-ASCII characters\n",
    "data[mask]\n",
    "\n",
    "#function to normalize text by removing accents and special characters\n",
    "def normalize_text(text): \n",
    "    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8') \n",
    "data['Product Name'] = data['Product Name'].apply(normalize_text)\n",
    "data.to_csv('Data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abc976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for invalid values like -ve values or unreasonable values in the numerical columns\n",
    "invalid_unitSolds=data[data['Units Sold']<0]\n",
    "invalid_unitPrice=data[data['Unit Price']<0]\n",
    "invalid_totalRevenue=data[data['Total Revenue']<0]\n",
    "\n",
    "print(invalid_unitSolds)\n",
    "print(invalid_unitPrice)\n",
    "print(invalid_totalRevenue)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c832f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) Handling outliers\n",
    "\n",
    "numeric_cols = data[['Units Sold', 'Unit Price', 'Total Revenue']] \n",
    "\n",
    "#printing the outliers\n",
    "for col in numeric_cols:\n",
    "    Q1=data[col].quantile(0.25)\n",
    "    Q3=data[col].quantile(0.75)\n",
    "    IQR=Q3-Q1\n",
    "    lower=Q1 - 1.5 * IQR\n",
    "    upper=Q3 + 1.5 * IQR\n",
    "    outliers=data[(data[col]<lower) | (data[col]>upper)]\n",
    "    #here we gave the data[col] col now is year and is now a series\n",
    "    #the series is undergoing a condition it will check if it's true and retrun a series of boolean\n",
    "    #now outlier is a dataframe that contains all the rows that have outliers in that specific column\n",
    "    # if not outliers.empty:\n",
    "    #     print(f\"\\nColumn '{col}' has outliers:\")\n",
    "    #     print(outliers[[col]])\n",
    "\n",
    "\n",
    "#using the box plot to visualize the outliers\n",
    "fig1,ax1=plt.subplots()\n",
    "fig2,ax2=plt.subplots()\n",
    "fig3,ax3=plt.subplots()\n",
    "ax1.boxplot(data['Units Sold'],vert=False,labels=['Units Sold'])\n",
    "ax1.set_title('Box plot for Units Sold')\n",
    "ax1.set_xlabel('No. of Units Sold')\n",
    "\n",
    "\n",
    "ax2.boxplot(data['Unit Price'],vert=False,labels=['Unit Price'])\n",
    "ax2.set_title('Box plot for Unit Price')\n",
    "ax2.set_xlabel('USD$')\n",
    "\n",
    "ax3.boxplot(data['Total Revenue'],vert=False,labels=['Total Revenue'])\n",
    "ax3.set_title('Box plot for Total Revenue')\n",
    "ax3.set_xlabel('USD$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#there is no outliers in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e32eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming the data to log scale to reduce the effect of outliers\n",
    "data['Unit Price']=np.log1p(data['Unit Price'])\n",
    "data['Total Revenue']=np.log1p(data['Total Revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf94192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#visualizing the data after log transformation\n",
    "fig2,ax2=plt.subplots()\n",
    "fig3,ax3=plt.subplots()\n",
    "\n",
    "ax2.boxplot(data['Unit Price'],vert=False,labels=['Unit Price'])\n",
    "ax2.set_title('Box plot for Unit Price')\n",
    "ax2.set_xlabel('USD$')\n",
    "\n",
    "ax3.boxplot(data['Total Revenue'],vert=False,labels=['Total Revenue'])\n",
    "ax3.set_title('Box plot for Total Revenue')\n",
    "ax3.set_xlabel('USD$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5520cfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction ID                               int64\n",
      "Date                                datetime64[ns]\n",
      "Product Name                                object\n",
      "Units Sold                                   int64\n",
      "Unit Price                                 float64\n",
      "Total Revenue                              float64\n",
      "Region_Asia                                  int64\n",
      "Region_Europe                                int64\n",
      "Region_North America                         int64\n",
      "Product Category_Beauty Products             int64\n",
      "Product Category_Books                       int64\n",
      "Product Category_Clothing                    int64\n",
      "Product Category_Electronics                 int64\n",
      "Product Category_Home Appliances             int64\n",
      "Product Category_Sports                      int64\n",
      "Payment Method_Credit Card                   int64\n",
      "Payment Method_Debit Card                    int64\n",
      "Payment Method_PayPal                        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_encoded=pd.get_dummies(data,columns=['Region','Product Category','Payment Method'])\n",
    "bool_cols = data_encoded.select_dtypes(include='bool').columns\n",
    "data_encoded[bool_cols] = data_encoded[bool_cols].astype(int)\n",
    "print(data_encoded.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "90bf4cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Units Sold  Unit Price  Total Revenue  Region_Asia  \\\n",
      "0 2024-01-01           2    6.908745       7.601392            0   \n",
      "1 2024-01-02           1    6.216586       6.216586            0   \n",
      "2 2024-01-03           3    4.262539       5.351716            1   \n",
      "3 2024-01-04           4    2.832625       4.173772            0   \n",
      "4 2024-01-05           1    4.510750       4.510750            0   \n",
      "\n",
      "   Region_Europe  Region_North America  Product Category_Beauty Products  \\\n",
      "0              0                     1                                 0   \n",
      "1              1                     0                                 0   \n",
      "2              0                     0                                 0   \n",
      "3              0                     1                                 0   \n",
      "4              1                     0                                 1   \n",
      "\n",
      "   Product Category_Books  Product Category_Clothing  \\\n",
      "0                       0                          0   \n",
      "1                       0                          0   \n",
      "2                       0                          1   \n",
      "3                       1                          0   \n",
      "4                       0                          0   \n",
      "\n",
      "   Product Category_Electronics  Product Category_Home Appliances  \\\n",
      "0                             1                                 0   \n",
      "1                             0                                 1   \n",
      "2                             0                                 0   \n",
      "3                             0                                 0   \n",
      "4                             0                                 0   \n",
      "\n",
      "   Product Category_Sports  Payment Method_Credit Card  \\\n",
      "0                        0                           1   \n",
      "1                        0                           0   \n",
      "2                        0                           0   \n",
      "3                        0                           1   \n",
      "4                        0                           0   \n",
      "\n",
      "   Payment Method_Debit Card  Payment Method_PayPal  \n",
      "0                          0                      0  \n",
      "1                          0                      1  \n",
      "2                          1                      0  \n",
      "3                          0                      0  \n",
      "4                          0                      1  \n"
     ]
    }
   ],
   "source": [
    "data_encoded=data_encoded.drop(['Product Name','Transaction ID'],axis=1)\n",
    "print(data_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a2b70823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Units Sold  Unit Price  Total Revenue  Region_Asia  Region_Europe  \\\n",
      "0           2    6.908745       7.601392            0              0   \n",
      "1           1    6.216586       6.216586            0              1   \n",
      "2           3    4.262539       5.351716            1              0   \n",
      "3           4    2.832625       4.173772            0              0   \n",
      "4           1    4.510750       4.510750            0              1   \n",
      "\n",
      "   Region_North America  Product Category_Beauty Products  \\\n",
      "0                     1                                 0   \n",
      "1                     0                                 0   \n",
      "2                     0                                 0   \n",
      "3                     1                                 0   \n",
      "4                     0                                 1   \n",
      "\n",
      "   Product Category_Books  Product Category_Clothing  \\\n",
      "0                       0                          0   \n",
      "1                       0                          0   \n",
      "2                       0                          1   \n",
      "3                       1                          0   \n",
      "4                       0                          0   \n",
      "\n",
      "   Product Category_Electronics  Product Category_Home Appliances  \\\n",
      "0                             1                                 0   \n",
      "1                             0                                 1   \n",
      "2                             0                                 0   \n",
      "3                             0                                 0   \n",
      "4                             0                                 0   \n",
      "\n",
      "   Product Category_Sports  Payment Method_Credit Card  \\\n",
      "0                        0                           1   \n",
      "1                        0                           0   \n",
      "2                        0                           0   \n",
      "3                        0                           1   \n",
      "4                        0                           0   \n",
      "\n",
      "   Payment Method_Debit Card  Payment Method_PayPal  Cluster  \n",
      "0                          0                      0        1  \n",
      "1                          0                      1        1  \n",
      "2                          1                      0        0  \n",
      "3                          0                      0        0  \n",
      "4                          0                      1        2  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohamed\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'Cleaned_Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#print(data_encoded.head())\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m data_encoded\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCleaned_Data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\mohamed\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mohamed\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3968\u001b[0m     path_or_buf,\n\u001b[0;32m   3969\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3970\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3971\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3972\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3973\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3974\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3975\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3976\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3977\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3978\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3979\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3980\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3981\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3982\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3983\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3984\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mohamed\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\mohamed\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    254\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    255\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    256\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    257\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\mohamed\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'Cleaned_Data.csv'"
     ]
    }
   ],
   "source": [
    "X=data_encoded.select_dtypes(include='number')\n",
    "print(X.head())\n",
    "kmeans=KMeans(n_clusters=3,random_state=123)\n",
    "data_encoded['Cluster']=kmeans.fit_predict(X)\n",
    "\n",
    "\n",
    "\n",
    "# Check average feature values per cluster\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Plot clusters\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=data_encoded['Cluster'], cmap='viridis', s=50)\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.title('K-Means Clusters (2D PCA)')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.show()\n",
    "#print(data_encoded.head())\n",
    "data_encoded.to_csv('Cleaned_Data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
