# Task 2 â€“ Data Pre-processing Practice

## ðŸš€ Overview  
This repository contains a data-pre-processing project focused on cleaning and preparing a raw dataset (sourced from Kaggle) for downstream analysis or machine learning. The goal is to turn unstructured or messy data into a clean and well-organized dataset ready for modelling or exploration.

## ðŸ“‚ Contents  
- `main.ipynb` â€“ The Jupyter notebook walking through the preprocessing pipeline step-by-step.  
- `Data.csv` â€“ The original raw dataset.  
- `Cleaned_Data.csv` â€“ The cleaned and processed version of the dataset.  
- `Notes.docx` â€“ A summary document of the preprocessing steps, insights, and transformations applied.  
- `README.md` â€“ This file.

## ðŸ§ª Whatâ€™s Covered  
In this project youâ€™ll see the following tasks tackled:  
- Data loading and initial overview (shape, column types, missing values).  
- Exploratory data analysis (visualizations, distributions, correlations).  
- Handling missing data through imputation or deletion.  
- Dealing with outliers and erroneous entries.  
- Encoding categorical variables (label encoding / one-hot encoding).  
- Standardizing or normalizing numerical features.  
- Feature selection, dropping redundant/unhelpful columns.  
- Saving the cleaned dataset for further use.

## ðŸ›  Setup & Usage  
1. Clone the repository:  
   ```bash
   git clone https://github.com/MohamedWalid2321/Task2-Data-Pre-processing.git